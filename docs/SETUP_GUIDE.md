# ğŸš€ Code Buddy MCP - Final Setup Steps

## Current Status âœ…
- âœ… All code complete and ready
- âœ… Railway PostgreSQL database deployed
- âœ… Configuration set to use Cohere embeddings
- âœ… Requirements updated with Cohere SDK

## What You Need to Do Next (15 minutes)

### Step 1: Install Dependencies (2 min)

Open a terminal in `C:\Repos\code_buddy_mcp` and run:

```bash
pip install -r requirements.txt
```

This will install all required packages including:
- FastMCP (MCP server framework)
- PostgreSQL drivers (psycopg2, SQLAlchemy, pgvector)
- Cohere SDK (for embeddings)
- Utilities (click, rich, python-dotenv)

### Step 2: Verify Database Connection (1 min)

Test the connection to your Railway database:

```bash
python test_db.py
```

Expected output:
```
ğŸ” Testing database connection...
âœ… Connection successful!
ğŸ“‹ Existing tables:
  (No tables found - database needs initialization)
ğŸ” pgvector extension: âœ… Installed
âœ… All checks passed!
```

### Step 3: Initialize Database Schema (2 min)

Create all tables, indexes, and functions:

```bash
python scripts/setup_database.py
```

This will:
- âœ… Enable pgvector extension
- âœ… Create workflows table (with vector support)
- âœ… Create categories table
- âœ… Create workflow_relationships table
- âœ… Create workflow_usage table (analytics)
- âœ… Create indexes for performance
- âœ… Seed initial categories
- âœ… Create materialized views

Expected output:
```
ğŸš€ Code Buddy - Database Setup
==================================================
ğŸ“¡ Connecting to database...
ğŸ” Testing connection...
âœ… Connection successful
ğŸ” Checking pgvector extension...
âœ… pgvector extension found
ğŸ“„ Executing schema from src/database/schema.sql...
âœ… Schema executed successfully
ğŸ” Verifying tables...
ğŸ“‹ Found tables:
  âœ… workflows
  âœ… workflow_relationships
  âœ… workflow_usage
  âœ… categories
==================================================
ğŸ‰ Database setup complete!
```

**Optional**: If you see "tables already exist" errors, run with `--reset` to start fresh:
```bash
python scripts/setup_database.py --reset
```

### Step 4: Prepare Your Workflows (5 min)

You have 118 workflows to import. Organize them in the `workflows/` directory:

```
workflows/
â”œâ”€â”€ development/           # Backend, frontend, API workflows
â”œâ”€â”€ data-engineering/      # ETL, pipelines, data quality
â”œâ”€â”€ devops/               # CI/CD, deployment, infrastructure
â”œâ”€â”€ architecture/         # System design, patterns
â”œâ”€â”€ project-management/   # Agile, planning, coordination
â””â”€â”€ discovery/            # Research, POCs, spikes
```

Each workflow should be a `.md` file with YAML frontmatter:

```markdown
---
title: Your Workflow Title
description: Brief description of what this workflow does
category: Development
subcategory: Backend
tags: [api, rest, python]
technologies: [Python, FastAPI, PostgreSQL]
complexity: intermediate
estimated_time_minutes: 45
use_cases:
  - Creating REST APIs
  - Building microservices
problem_statement: How to create production-ready API endpoints
---

# Workflow Content Here

Your actual workflow content in markdown...
```

### Step 5: Import Workflows (2 min)

Import all your workflows with automatic embedding generation:

```bash
python scripts/import_workflows.py --directory ./workflows
```

This will:
- ğŸ“ Scan all `.md` files in subdirectories
- ğŸ“ Parse YAML frontmatter
- ğŸ§  Generate embeddings using Cohere
- ğŸ’¾ Store in PostgreSQL with vector support
- ğŸ”„ Skip duplicates (based on content hash)
- âœ… Show progress for each file

Expected output:
```
ğŸš€ Workflow Import Tool
========================================
ğŸ“ Scanning ./workflows for .md files...
âœ… Found 118 workflow files

ğŸ”„ Processing workflows...
[1/118] âœ… fastapi-endpoint-workflow.md
[2/118] âœ… database-migration-workflow.md
[3/118] âœ… cicd-pipeline-setup.md
...
[118/118] âœ… api-versioning-strategy.md

ğŸ“Š Import Summary:
âœ… Successfully imported: 118
â­ï¸  Skipped (unchanged): 0
âŒ Failed: 0

ğŸ‰ All workflows imported!
Next: python src/server.py
```

**Time estimate**: ~30 seconds for 118 workflows (Cohere is fast!)

### Step 6: Start MCP Server (1 min)

Launch the MCP server:

```bash
python src/server.py
```

Expected output:
```
ğŸš€ Starting Code Buddy MCP Server
========================================
ğŸ“¡ Connecting to database...
âœ… Database connection successful
ğŸ” Found 118 active workflows
ğŸ§  Initialized Cohere embeddings (embed-english-v3.0)
âœ… Server ready!

Available tools:
  - search_workflows
  - get_workflow
  - list_categories
  - get_prerequisites
  - track_usage

Listening for MCP connections...
```

**Keep this terminal window open!** The server needs to stay running.

### Step 7: Configure Claude Desktop (2 min)

#### Windows
Edit: `%APPDATA%\Claude\claude_desktop_config.json`

```json
{
  "mcpServers": {
    "code-buddy": {
      "command": "python",
      "args": ["C:\\Repos\\code_buddy_mcp\\src\\server.py"],
      "env": {
        "DATABASE_URL": "postgresql://postgres:NCZNJ9yWWcpGTLKm-vvpNeuA3J-vvbuH@shortline.proxy.rlwy.net:38056/railway",
        "COHERE_API_KEY": "JSbTlybyl89CpMGaAlcLKVtARcBBYZZqLBASC1jQ",
        "EMBEDDING_PROVIDER": "cohere",
        "EMBEDDING_MODEL": "embed-english-v3.0",
        "EMBEDDING_DIMENSIONS": "1024"
      }
    }
  }
}
```

**Important**: 
- Replace backslashes with double backslashes in path: `\\`
- Use your actual DATABASE_URL and COHERE_API_KEY from `.env`

#### Mac
Edit: `~/Library/Application Support/Claude/claude_desktop_config.json`

```json
{
  "mcpServers": {
    "code-buddy": {
      "command": "python",
      "args": ["/path/to/code_buddy_mcp/src/server.py"],
      "env": {
        "DATABASE_URL": "your-database-url",
        "COHERE_API_KEY": "your-cohere-key",
        "EMBEDDING_PROVIDER": "cohere",
        "EMBEDDING_MODEL": "embed-english-v3.0",
        "EMBEDDING_DIMENSIONS": "1024"
      }
    }
  }
}
```

### Step 8: Restart Claude Desktop (1 min)

1. Quit Claude Desktop completely
2. Relaunch Claude Desktop
3. Look for "ğŸ”§" icon in the text input area (shows MCP tools available)

### Step 9: Test It! (2 min)

Try these queries in Claude:

**Test 1: Simple Search**
```
Search for workflows about creating REST API endpoints
```

Expected: Claude will use the `search_workflows` tool and return relevant FastAPI workflows

**Test 2: Filtered Search**
```
Find Python workflows for data pipelines that take less than 30 minutes
```

Expected: Filtered results matching your criteria

**Test 3: Browse Categories**
```
What workflow categories are available?
```

Expected: List of categories (Development, Data Engineering, etc.)

**Test 4: Prerequisites**
```
Show me the prerequisite chain for microservices architecture workflow
```

Expected: Dependency tree of workflows to complete first

## ğŸ‰ Success Indicators

You'll know it's working when:
- âœ… MCP server starts without errors
- âœ… Claude shows "code-buddy" in available tools
- âœ… Searches return relevant workflows
- âœ… Token usage is ~6-10KB instead of 236KB
- âœ… Results include similarity scores
- âœ… Can see prerequisite relationships

## ğŸ“Š Performance Expectations

| Metric | Expected Value |
|--------|---------------|
| Import Speed | ~0.5s per workflow |
| Search Response | <100ms |
| Token Usage | 6-10KB per query |
| Accuracy | 95%+ relevance |

## ğŸ› Troubleshooting

### "Module not found" errors
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### "Database connection failed"
- Verify DATABASE_URL in `.env` matches Railway
- Check Railway database is running
- Test with: `python test_db.py`

### "pgvector not installed"
Railway includes pgvector by default. If needed:
```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

### "No workflows found" after import
- Check files are in `.md` format
- Verify YAML frontmatter format
- Run import with verbose flag: `--verbose`

### MCP server not showing in Claude
- Verify claude_desktop_config.json syntax (JSON must be valid)
- Check file path uses double backslashes on Windows
- Restart Claude Desktop completely
- Check server is running: `python src/server.py` should show "Listening..."

## ğŸ“ˆ Next: Add Your 118 Workflows!

Once basic setup works with the 2 example workflows:

1. **Organize Your Files**
   - Move all 118 workflow files to appropriate subdirectories
   - Ensure each has proper frontmatter

2. **Bulk Import**
   ```bash
   python scripts/import_workflows.py --directory ./workflows
   ```

3. **Verify Count**
   ```bash
   python -c "
   from src.database.connection import DatabaseConnection
   from dotenv import load_dotenv
   import os
   
   load_dotenv()
   db = DatabaseConnection(os.getenv('DATABASE_URL'))
   with db.get_session() as session:
       from sqlalchemy import text
       result = session.execute(text('SELECT COUNT(*) FROM workflows'))
       print(f'Total workflows: {result.scalar()}')
   "
   ```

4. **Test Advanced Queries**
   - "Find all Python workflows"
   - "What are the most popular workflows?"
   - "Show me beginner-level data engineering workflows"

## ğŸ¯ What You Get

âœ… **Intelligent Search**: Semantic understanding of queries  
âœ… **Token Efficiency**: 39x reduction (236KB â†’ 6-10KB)  
âœ… **Scalability**: Handles 1000+ workflows  
âœ… **Analytics**: Track usage and helpfulness  
âœ… **Relationships**: Prerequisite chains  
âœ… **Cloud-Based**: Accessible from any computer  

## ğŸ“š Documentation

- **Quick Start**: `docs/QUICKSTART.md`
- **API Reference**: `docs/API.md`
- **Deployment**: `docs/DEPLOYMENT.md`
- **Status**: `PROJECT_STATUS.md`

---

**Total Setup Time**: 15-20 minutes

**Ready to start?** Begin with Step 1! ğŸš€
